{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import pytse_client as tse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# tickers = tse.download(symbols=\"all\", write_to_csv=True)\n",
    "\n",
    "Device = (\"cuda\"\n",
    "          if torch.cuda.is_available()\n",
    "          else \"cpu\"\n",
    ")\n",
    "print(f\"Using {Device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym=\"آپ\"\n",
    "ticker=tse.Ticker(sym)\n",
    "length=ticker.history.shape[0]\n",
    "train_length = int(np.floor(length*0.90))\n",
    "test_length = length - train_length\n",
    "days_history=100\n",
    "days_predict=30\n",
    "\n",
    "# Now we extract some portion of the first sequences of data for train\n",
    "X_train=np.zeros([train_length - days_history - days_predict , days_history,5])\n",
    "Y_train=np.zeros([train_length - days_history - days_predict , days_predict])\n",
    "for i in range(train_length - days_history - days_predict):\n",
    "    m = ticker.history.loc[i : i + days_history - 1].to_numpy()\n",
    "    X_train[i,:,:] = np.array([(m[:,9]-m[:,8])/m[:,8] * 100 , m[:,7]/1e3 , m[:,6]/1e6 , m[:,2] , m[:,3]]).T\n",
    "    m = ticker.history.loc[i + days_history : i + days_history - 1 + days_predict].to_numpy()\n",
    "    Y_train[i,:] = (m[:,9]-m[:,8])/m[:,8] * 100\n",
    "\n",
    "# Now we extract some portion of the last sequences of data for test\n",
    "X_test=np.zeros([test_length - days_predict , days_history,5])\n",
    "Y_test=np.zeros([test_length - days_predict , days_predict])\n",
    "for i in range(test_length - days_predict):\n",
    "    j = i + train_length - days_history\n",
    "    m = ticker.history.loc[j : j + days_history - 1].to_numpy()\n",
    "    X_test[i,:,:] = np.array([(m[:,9]-m[:,8])/m[:,8] * 100 , m[:,7]/1e3 , m[:,6]/1e6 , m[:,2] , m[:,3]]).T\n",
    "    m = ticker.history.loc[j + days_history : j + days_history - 1 + days_predict].to_numpy()\n",
    "    Y_test[i,:] = (m[:,9]-m[:,8])/m[:,8] * 100\n",
    "\n",
    "train_arr = np.arange(train_length - days_history - days_predict - 1)\n",
    "train_idx = np.random.permutation(train_arr)\n",
    "X_train = X_train[train_idx]\n",
    "Y_train = Y_train[train_idx]\n",
    "\n",
    "test_arr = np.arange(test_length - days_predict - 1)\n",
    "test_idx = np.random.permutation(test_arr)\n",
    "X_test = X_test[test_idx]\n",
    "Y_test = Y_test[test_idx]\n",
    "X_train = torch.from_numpy(X_train).to(device=Device,dtype=torch.float32)\n",
    "Y_train = torch.from_numpy(Y_train).to(device=Device,dtype=torch.float32)\n",
    "\n",
    "X_test = torch.from_numpy(X_test).to(device=Device,dtype=torch.float32)\n",
    "Y_test = torch.from_numpy(Y_test).to(device=Device,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        n=64\n",
    "        super().__init__()\n",
    "        self.Lin1 = nn.Linear(input_size,2*n)\n",
    "        self.Lin2 = nn.Linear(2*n,4*n)\n",
    "        self.Lin3 = nn.Linear(4*n,2*n)\n",
    "        self.Lin4 = nn.Linear(2*n,n)\n",
    "        self.Lin5 = nn.Linear(n,output_size)\n",
    "        self.activation1 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        #self.activation2 = nn.Tanh()\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "        self.norm = nn.BatchNorm1d(4*n)\n",
    "    def forward(self, x):\n",
    "        x = self.Lin1(x)\n",
    "        for i in range(1):\n",
    "            x_ = x\n",
    "            x = self.activation1(x)\n",
    "            x = self.drop(x) ###\n",
    "            x = self.Lin2(x)\n",
    "            x = self.norm(x) ####\n",
    "            x = self.activation1(x)\n",
    "            x = self.drop(x) ###\n",
    "            x = self.Lin3(x)\n",
    "            x = self.activation1(x)\n",
    "            x = self.drop(x) ###\n",
    "            x = x + x_\n",
    "\n",
    "        x = self.Lin4(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.drop(x) ###\n",
    "        x = self.Lin5(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.drop(x) ###\n",
    "        return x\n",
    "\n",
    "model=Model(days_history*5,days_predict).to(device=Device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "LossFn = nn.MSELoss()\n",
    "#for p in model.parameters():\n",
    "#    p.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: train loss is 213418.953125 & test loss is 683.7254028320312 & accuracy is %-1155.73681640625\n",
      "1: train loss is 16470.58203125 & test loss is 252.45220947265625 & accuracy is %-663.0224609375\n",
      "2: train loss is 5023.56298828125 & test loss is 96.41730499267578 & accuracy is %-362.92034912109375\n",
      "3: train loss is 2562.736572265625 & test loss is 53.04490280151367 & accuracy is %-237.9883270263672\n",
      "4: train loss is 1570.24609375 & test loss is 39.484100341796875 & accuracy is %-182.51138305664062\n",
      "5: train loss is 1410.664306640625 & test loss is 32.99215316772461 & accuracy is %-157.9637451171875\n",
      "6: train loss is 1125.5460205078125 & test loss is 32.3682746887207 & accuracy is %-155.40513610839844\n",
      "7: train loss is 1029.1773681640625 & test loss is 30.03194236755371 & accuracy is %-142.7440948486328\n",
      "8: train loss is 875.9548950195312 & test loss is 23.52391815185547 & accuracy is %-109.6984634399414\n",
      "9: train loss is 728.3043823242188 & test loss is 23.205217361450195 & accuracy is %-107.30242919921875\n",
      "10: train loss is 776.4082641601562 & test loss is 28.6450138092041 & accuracy is %-133.8347625732422\n",
      "11: train loss is 680.1455078125 & test loss is 20.8702335357666 & accuracy is %-95.67106628417969\n",
      "12: train loss is 567.6163940429688 & test loss is 17.24544334411621 & accuracy is %-74.01529693603516\n",
      "13: train loss is 608.3091430664062 & test loss is 17.000518798828125 & accuracy is %-71.50328063964844\n",
      "14: train loss is 630.396484375 & test loss is 21.41381072998047 & accuracy is %-97.85746002197266\n",
      "15: train loss is 714.8126220703125 & test loss is 36.391265869140625 & accuracy is %-163.78384399414062\n",
      "16: train loss is 1053.624755859375 & test loss is 29.756444931030273 & accuracy is %-139.23568725585938\n",
      "17: train loss is 652.8142700195312 & test loss is 17.54273223876953 & accuracy is %-76.89079284667969\n",
      "18: train loss is 632.0516357421875 & test loss is 20.26108741760254 & accuracy is %-92.47176361083984\n",
      "19: train loss is 520.5433959960938 & test loss is 14.137852668762207 & accuracy is %-52.072967529296875\n",
      "20: train loss is 449.39581298828125 & test loss is 15.76722240447998 & accuracy is %-65.09770202636719\n",
      "21: train loss is 382.0379638671875 & test loss is 13.028236389160156 & accuracy is %-44.96425247192383\n",
      "22: train loss is 417.6653747558594 & test loss is 19.555416107177734 & accuracy is %-90.69843292236328\n",
      "23: train loss is 368.799560546875 & test loss is 17.4439697265625 & accuracy is %-76.64505004882812\n",
      "24: train loss is 407.65997314453125 & test loss is 17.888837814331055 & accuracy is %-79.50263977050781\n",
      "25: train loss is 410.61981201171875 & test loss is 14.7990140914917 & accuracy is %-57.423763275146484\n",
      "26: train loss is 367.8663330078125 & test loss is 15.588963508605957 & accuracy is %-62.72429656982422\n",
      "27: train loss is 383.2813415527344 & test loss is 18.68422508239746 & accuracy is %-82.69088745117188\n",
      "28: train loss is 402.62750244140625 & test loss is 19.604127883911133 & accuracy is %-89.65126037597656\n",
      "29: train loss is 378.2977294921875 & test loss is 17.072593688964844 & accuracy is %-73.30528259277344\n",
      "30: train loss is 397.0184631347656 & test loss is 13.756245613098145 & accuracy is %-51.116615295410156\n",
      "31: train loss is 331.01092529296875 & test loss is 10.559246063232422 & accuracy is %-26.582002639770508\n",
      "32: train loss is 284.7940368652344 & test loss is 10.795701026916504 & accuracy is %-29.239255905151367\n",
      "33: train loss is 337.2754821777344 & test loss is 14.62305736541748 & accuracy is %-57.26658630371094\n",
      "34: train loss is 325.60723876953125 & test loss is 17.54829978942871 & accuracy is %-75.14788055419922\n",
      "35: train loss is 417.9302673339844 & test loss is 16.507095336914062 & accuracy is %-70.57305145263672\n",
      "36: train loss is 311.05975341796875 & test loss is 15.877667427062988 & accuracy is %-66.13563537597656\n",
      "37: train loss is 320.8896484375 & test loss is 15.998852729797363 & accuracy is %-67.38459014892578\n",
      "38: train loss is 238.2700653076172 & test loss is 10.986926078796387 & accuracy is %-31.36920928955078\n",
      "39: train loss is 238.41110229492188 & test loss is 11.093650817871094 & accuracy is %-32.51072692871094\n",
      "40: train loss is 215.82237243652344 & test loss is 10.524859428405762 & accuracy is %-27.670230865478516\n",
      "41: train loss is 248.72348022460938 & test loss is 14.443818092346191 & accuracy is %-56.76422119140625\n",
      "42: train loss is 294.59600830078125 & test loss is 13.283858299255371 & accuracy is %-47.863548278808594\n",
      "43: train loss is 256.99853515625 & test loss is 13.350724220275879 & accuracy is %-47.58132553100586\n",
      "44: train loss is 260.5356140136719 & test loss is 10.107789039611816 & accuracy is %-24.024620056152344\n",
      "45: train loss is 284.67010498046875 & test loss is 18.782569885253906 & accuracy is %-82.69229888916016\n",
      "46: train loss is 279.7822570800781 & test loss is 10.921424865722656 & accuracy is %-30.958812713623047\n",
      "47: train loss is 278.7966613769531 & test loss is 14.116177558898926 & accuracy is %-53.84526062011719\n",
      "48: train loss is 286.8374938964844 & test loss is 14.405643463134766 & accuracy is %-56.643001556396484\n",
      "49: train loss is 290.7526550292969 & test loss is 18.401193618774414 & accuracy is %-80.18473052978516\n",
      "50: train loss is 381.5484619140625 & test loss is 19.57944679260254 & accuracy is %-86.7991943359375\n",
      "51: train loss is 371.5772705078125 & test loss is 13.615520477294922 & accuracy is %-49.59982681274414\n",
      "52: train loss is 261.6384582519531 & test loss is 11.230903625488281 & accuracy is %-32.60860061645508\n",
      "53: train loss is 294.2121887207031 & test loss is 18.79430389404297 & accuracy is %-83.40351104736328\n",
      "54: train loss is 414.70501708984375 & test loss is 15.80628490447998 & accuracy is %-63.43214416503906\n",
      "55: train loss is 343.3546447753906 & test loss is 10.249789237976074 & accuracy is %-26.284250259399414\n",
      "56: train loss is 240.4258270263672 & test loss is 13.389681816101074 & accuracy is %-47.39640808105469\n",
      "57: train loss is 364.0085754394531 & test loss is 19.099407196044922 & accuracy is %-84.051025390625\n",
      "58: train loss is 302.49969482421875 & test loss is 12.432509422302246 & accuracy is %-41.64697265625\n",
      "59: train loss is 171.94003295898438 & test loss is 11.798001289367676 & accuracy is %-36.77363586425781\n",
      "60: train loss is 232.9176788330078 & test loss is 12.46114444732666 & accuracy is %-42.75367736816406\n",
      "61: train loss is 229.21376037597656 & test loss is 10.712687492370605 & accuracy is %-29.176193237304688\n",
      "62: train loss is 277.1278381347656 & test loss is 11.937187194824219 & accuracy is %-38.52193832397461\n",
      "63: train loss is 320.39404296875 & test loss is 29.251413345336914 & accuracy is %-139.46116638183594\n",
      "64: train loss is 372.96734619140625 & test loss is 12.859660148620605 & accuracy is %-45.03326416015625\n",
      "65: train loss is 298.8172912597656 & test loss is 17.93900489807129 & accuracy is %-78.54263305664062\n",
      "66: train loss is 228.0673828125 & test loss is 10.924049377441406 & accuracy is %-30.8225154876709\n",
      "67: train loss is 309.4844055175781 & test loss is 14.289862632751465 & accuracy is %-54.92279052734375\n",
      "68: train loss is 289.8269348144531 & test loss is 14.330333709716797 & accuracy is %-54.60047149658203\n",
      "69: train loss is 483.0138244628906 & test loss is 35.17616653442383 & accuracy is %-161.7418670654297\n",
      "70: train loss is 615.7498779296875 & test loss is 34.12179946899414 & accuracy is %-159.3422393798828\n",
      "71: train loss is 458.0907897949219 & test loss is 21.201265335083008 & accuracy is %-96.10494232177734\n",
      "72: train loss is 250.81947326660156 & test loss is 16.77924919128418 & accuracy is %-70.70487976074219\n",
      "73: train loss is 443.9200134277344 & test loss is 14.72268009185791 & accuracy is %-59.19878387451172\n",
      "74: train loss is 247.589599609375 & test loss is 8.878863334655762 & accuracy is %-14.309718132019043\n",
      "75: train loss is 142.28793334960938 & test loss is 9.702815055847168 & accuracy is %-20.66610336303711\n",
      "76: train loss is 187.6280517578125 & test loss is 10.790410041809082 & accuracy is %-29.7143611907959\n",
      "77: train loss is 172.3457794189453 & test loss is 10.23108196258545 & accuracy is %-24.777360916137695\n",
      "78: train loss is 142.2952880859375 & test loss is 7.414883136749268 & accuracy is %-1.8136614561080933\n",
      "79: train loss is 129.50889587402344 & test loss is 8.140788078308105 & accuracy is %-8.07341194152832\n",
      "80: train loss is 121.09624481201172 & test loss is 7.387123107910156 & accuracy is %-1.7779598236083984\n",
      "81: train loss is 199.05345153808594 & test loss is 24.2915096282959 & accuracy is %-108.46849822998047\n",
      "82: train loss is 1749.9183349609375 & test loss is 72.1874771118164 & accuracy is %-286.4686584472656\n",
      "83: train loss is 3344.899169921875 & test loss is 152.85186767578125 & accuracy is %-491.7350158691406\n",
      "84: train loss is 1146.4298095703125 & test loss is 30.022607803344727 & accuracy is %-137.07830810546875\n",
      "85: train loss is 497.19805908203125 & test loss is 25.099267959594727 & accuracy is %-117.3278579711914\n",
      "86: train loss is 442.53826904296875 & test loss is 22.49102210998535 & accuracy is %-104.25367736816406\n",
      "87: train loss is 341.776611328125 & test loss is 32.6697883605957 & accuracy is %-149.981201171875\n",
      "88: train loss is 472.7036437988281 & test loss is 86.31893157958984 & accuracy is %-317.6160583496094\n",
      "89: train loss is 2810.797607421875 & test loss is 85.27369689941406 & accuracy is %-315.6263732910156\n",
      "90: train loss is 1121.052978515625 & test loss is 42.17216110229492 & accuracy is %-195.08657836914062\n",
      "91: train loss is 494.7553405761719 & test loss is 15.704460144042969 & accuracy is %-65.94122314453125\n",
      "92: train loss is 252.6309356689453 & test loss is 11.759754180908203 & accuracy is %-36.72077560424805\n",
      "93: train loss is 138.19589233398438 & test loss is 10.51494312286377 & accuracy is %-27.470726013183594\n",
      "94: train loss is 176.0645751953125 & test loss is 13.308731079101562 & accuracy is %-47.478206634521484\n",
      "95: train loss is 145.52716064453125 & test loss is 7.579370975494385 & accuracy is %-3.9462757110595703\n",
      "96: train loss is 86.23884582519531 & test loss is 6.031612396240234 & accuracy is %9.234356880187988\n",
      "97: train loss is 67.0524673461914 & test loss is 6.310401916503906 & accuracy is %6.876618385314941\n",
      "98: train loss is 89.71260070800781 & test loss is 7.075165271759033 & accuracy is %0.6528581976890564\n",
      "99: train loss is 134.9158172607422 & test loss is 7.2110443115234375 & accuracy is %-0.3403909206390381\n",
      "100: train loss is 97.73493957519531 & test loss is 5.858862400054932 & accuracy is %10.559012413024902\n",
      "101: train loss is 85.32998657226562 & test loss is 6.979227066040039 & accuracy is %1.6750719547271729\n",
      "102: train loss is 78.07172393798828 & test loss is 6.50128698348999 & accuracy is %5.227082252502441\n",
      "103: train loss is 834.6923828125 & test loss is 44.6859016418457 & accuracy is %-199.47332763671875\n",
      "104: train loss is 425.94940185546875 & test loss is 13.015792846679688 & accuracy is %-45.71312713623047\n",
      "105: train loss is 153.24440002441406 & test loss is 10.282872200012207 & accuracy is %-25.026508331298828\n",
      "106: train loss is 114.22920227050781 & test loss is 6.2274298667907715 & accuracy is %7.561211109161377\n",
      "107: train loss is 81.39192199707031 & test loss is 6.552238941192627 & accuracy is %4.496698379516602\n",
      "108: train loss is 117.80732727050781 & test loss is 8.91158676147461 & accuracy is %-14.645271301269531\n",
      "109: train loss is 99.24378204345703 & test loss is 6.45184326171875 & accuracy is %5.950888633728027\n",
      "110: train loss is 79.71273040771484 & test loss is 6.611138820648193 & accuracy is %4.586000442504883\n",
      "111: train loss is 68.17705535888672 & test loss is 7.3873372077941895 & accuracy is %-1.8487136363983154\n",
      "112: train loss is 151.78219604492188 & test loss is 7.947094440460205 & accuracy is %-7.07182502746582\n",
      "113: train loss is 82.60978698730469 & test loss is 5.923219203948975 & accuracy is %9.937557220458984\n",
      "114: train loss is 61.967201232910156 & test loss is 5.472117900848389 & accuracy is %13.474220275878906\n",
      "115: train loss is 68.09303283691406 & test loss is 6.803203582763672 & accuracy is %2.7920241355895996\n",
      "116: train loss is 67.01771545410156 & test loss is 5.302774906158447 & accuracy is %14.987650871276855\n",
      "117: train loss is 12832.822265625 & test loss is 5547.419921875 & accuracy is %-3293.982666015625\n",
      "118: train loss is 628539.125 & test loss is 43049.4375 & accuracy is %-9396.5361328125\n",
      "119: train loss is 278108.09375 & test loss is 5424.40576171875 & accuracy is %-3336.226318359375\n",
      "120: train loss is 42759.2265625 & test loss is 994.5530395507812 & accuracy is %-1334.4847412109375\n",
      "121: train loss is 11298.8212890625 & test loss is 418.0118103027344 & accuracy is %-839.9310302734375\n",
      "122: train loss is 4751.1044921875 & test loss is 160.66664123535156 & accuracy is %-447.83349609375\n",
      "123: train loss is 2218.192138671875 & test loss is 88.8842544555664 & accuracy is %-316.3845520019531\n",
      "124: train loss is 1605.029541015625 & test loss is 62.314056396484375 & accuracy is %-237.5021209716797\n",
      "125: train loss is 891.3400268554688 & test loss is 31.68684196472168 & accuracy is %-132.49700927734375\n",
      "126: train loss is 635.5451049804688 & test loss is 34.70436477661133 & accuracy is %-145.524658203125\n",
      "127: train loss is 584.339111328125 & test loss is 23.747968673706055 & accuracy is %-99.79601287841797\n",
      "128: train loss is 485.68792724609375 & test loss is 33.56052017211914 & accuracy is %-150.71185302734375\n",
      "129: train loss is 656.5985717773438 & test loss is 31.0723819732666 & accuracy is %-128.02943420410156\n",
      "130: train loss is 496.4107360839844 & test loss is 19.537118911743164 & accuracy is %-79.906982421875\n",
      "131: train loss is 325.358154296875 & test loss is 21.209609985351562 & accuracy is %-87.46053314208984\n",
      "132: train loss is 332.2424621582031 & test loss is 20.481290817260742 & accuracy is %-86.03496551513672\n",
      "133: train loss is 234.2627716064453 & test loss is 11.268829345703125 & accuracy is %-30.32311248779297\n",
      "134: train loss is 207.0208740234375 & test loss is 10.76056957244873 & accuracy is %-27.028278350830078\n",
      "135: train loss is 212.6519012451172 & test loss is 11.59403133392334 & accuracy is %-32.56272506713867\n",
      "136: train loss is 202.0980987548828 & test loss is 11.902852058410645 & accuracy is %-35.27494812011719\n",
      "137: train loss is 184.53009033203125 & test loss is 12.748672485351562 & accuracy is %-37.882511138916016\n",
      "138: train loss is 212.6632843017578 & test loss is 12.9700345993042 & accuracy is %-44.04784393310547\n",
      "139: train loss is 187.69920349121094 & test loss is 11.658162117004395 & accuracy is %-32.12801742553711\n",
      "140: train loss is 182.87286376953125 & test loss is 13.43264389038086 & accuracy is %-43.83749008178711\n",
      "141: train loss is 188.6638641357422 & test loss is 10.067660331726074 & accuracy is %-23.09115982055664\n",
      "142: train loss is 163.13671875 & test loss is 12.508708953857422 & accuracy is %-38.71742248535156\n",
      "143: train loss is 182.27810668945312 & test loss is 10.552149772644043 & accuracy is %-25.829463958740234\n",
      "144: train loss is 124.45201873779297 & test loss is 8.2278413772583 & accuracy is %-8.558592796325684\n",
      "145: train loss is 118.9957275390625 & test loss is 8.984678268432617 & accuracy is %-14.64558219909668\n",
      "146: train loss is 206.9141082763672 & test loss is 11.241503715515137 & accuracy is %-30.080245971679688\n",
      "147: train loss is 162.41262817382812 & test loss is 8.260149955749512 & accuracy is %-8.919605255126953\n",
      "148: train loss is 192.02906799316406 & test loss is 12.814499855041504 & accuracy is %-41.764686584472656\n",
      "149: train loss is 190.6049041748047 & test loss is 10.720330238342285 & accuracy is %-27.23307991027832\n",
      "150: train loss is 220.54824829101562 & test loss is 8.716804504394531 & accuracy is %-12.473241806030273\n",
      "151: train loss is 143.27452087402344 & test loss is 8.028044700622559 & accuracy is %-6.87336540222168\n",
      "152: train loss is 114.76029205322266 & test loss is 7.900234699249268 & accuracy is %-5.913123607635498\n",
      "153: train loss is 131.1722869873047 & test loss is 8.581771850585938 & accuracy is %-10.922125816345215\n",
      "154: train loss is 141.7373504638672 & test loss is 15.757041931152344 & accuracy is %-49.72826385498047\n",
      "155: train loss is 260.2119445800781 & test loss is 24.638097763061523 & accuracy is %-95.18363189697266\n",
      "156: train loss is 1418.69287109375 & test loss is 55.93046188354492 & accuracy is %-222.22048950195312\n",
      "157: train loss is 704.6513671875 & test loss is 28.827295303344727 & accuracy is %-118.15015411376953\n",
      "158: train loss is 342.2578430175781 & test loss is 16.9056453704834 & accuracy is %-63.08490753173828\n",
      "159: train loss is 180.7151336669922 & test loss is 8.281655311584473 & accuracy is %-9.035465240478516\n",
      "160: train loss is 93.37574005126953 & test loss is 6.726747035980225 & accuracy is %3.393044948577881\n",
      "161: train loss is 89.79267120361328 & test loss is 7.7507452964782715 & accuracy is %-4.342986583709717\n",
      "162: train loss is 107.24018859863281 & test loss is 7.164618968963623 & accuracy is %-0.11847781389951706\n",
      "163: train loss is 78.70494079589844 & test loss is 6.302369594573975 & accuracy is %6.913567543029785\n",
      "164: train loss is 85.30435943603516 & test loss is 7.617401123046875 & accuracy is %-3.153545379638672\n",
      "165: train loss is 167.9283447265625 & test loss is 13.7047119140625 & accuracy is %-43.83025360107422\n",
      "166: train loss is 169.51657104492188 & test loss is 9.01901912689209 & accuracy is %-14.990811347961426\n",
      "167: train loss is 151.11056518554688 & test loss is 8.3427734375 & accuracy is %-9.812845230102539\n",
      "168: train loss is 127.16149139404297 & test loss is 10.718533515930176 & accuracy is %-23.999523162841797\n",
      "169: train loss is 116.80953216552734 & test loss is 10.703900337219238 & accuracy is %-26.797887802124023\n",
      "170: train loss is 197.3080291748047 & test loss is 12.181556701660156 & accuracy is %-38.191585540771484\n",
      "171: train loss is 235.14645385742188 & test loss is 14.427120208740234 & accuracy is %-52.49066925048828\n",
      "172: train loss is 142.41696166992188 & test loss is 8.391005516052246 & accuracy is %-8.592896461486816\n",
      "173: train loss is 101.5661392211914 & test loss is 6.4483208656311035 & accuracy is %5.621403694152832\n",
      "174: train loss is 116.43608856201172 & test loss is 7.9861297607421875 & accuracy is %-6.873569011688232\n",
      "175: train loss is 98.73738098144531 & test loss is 7.937389850616455 & accuracy is %-4.983012676239014\n",
      "176: train loss is 106.52782440185547 & test loss is 7.923290729522705 & accuracy is %-6.4832305908203125\n",
      "177: train loss is 105.36974334716797 & test loss is 6.356924533843994 & accuracy is %6.47723913192749\n",
      "178: train loss is 73.63721466064453 & test loss is 5.923253536224365 & accuracy is %9.845295906066895\n",
      "179: train loss is 1337.669189453125 & test loss is 360.7873229980469 & accuracy is %-756.7332153320312\n",
      "180: train loss is 10265.8544921875 & test loss is 300.3387756347656 & accuracy is %-703.853515625\n",
      "181: train loss is 4418.38232421875 & test loss is 152.6110382080078 & accuracy is %-442.8896789550781\n",
      "182: train loss is 1310.7359619140625 & test loss is 27.719100952148438 & accuracy is %-118.42526245117188\n",
      "183: train loss is 293.9901428222656 & test loss is 10.375442504882812 & accuracy is %-24.879880905151367\n",
      "184: train loss is 179.50904846191406 & test loss is 8.02354907989502 & accuracy is %-6.700562477111816\n",
      "185: train loss is 86.5136947631836 & test loss is 10.616790771484375 & accuracy is %-22.133331298828125\n",
      "186: train loss is 107.37992858886719 & test loss is 5.504968166351318 & accuracy is %12.785983085632324\n",
      "187: train loss is 44.83917236328125 & test loss is 5.301380157470703 & accuracy is %14.394196510314941\n",
      "188: train loss is 48.060218811035156 & test loss is 5.431684494018555 & accuracy is %13.109695434570312\n",
      "189: train loss is 48.729949951171875 & test loss is 6.188574314117432 & accuracy is %7.574480056762695\n",
      "190: train loss is 58.281700134277344 & test loss is 5.300083160400391 & accuracy is %14.406177520751953\n",
      "191: train loss is 41.104915618896484 & test loss is 5.39182710647583 & accuracy is %13.760482788085938\n",
      "192: train loss is 42.51598358154297 & test loss is 4.949909210205078 & accuracy is %17.128068923950195\n",
      "193: train loss is 62.11995315551758 & test loss is 7.566888332366943 & accuracy is %-3.9738845825195312\n",
      "194: train loss is 176.83462524414062 & test loss is 10.6372709274292 & accuracy is %-22.529502868652344\n",
      "195: train loss is 110.11630249023438 & test loss is 7.192973613739014 & accuracy is %-0.9212191104888916\n",
      "196: train loss is 69.1135025024414 & test loss is 5.613836765289307 & accuracy is %12.086918830871582\n",
      "197: train loss is 40.250816345214844 & test loss is 5.033344745635986 & accuracy is %16.595067977905273\n",
      "198: train loss is 44.54481506347656 & test loss is 5.3687286376953125 & accuracy is %13.83948040008545\n",
      "199: train loss is 45.548099517822266 & test loss is 5.704989910125732 & accuracy is %11.594808578491211\n",
      "200: train loss is 55.16010665893555 & test loss is 6.402287006378174 & accuracy is %6.024218559265137\n",
      "201: train loss is 135.6190948486328 & test loss is 11.416183471679688 & accuracy is %-30.598426818847656\n",
      "202: train loss is 172.17730712890625 & test loss is 7.262814044952393 & accuracy is %-0.6826374530792236\n",
      "203: train loss is 107.12515258789062 & test loss is 6.7158942222595215 & accuracy is %3.3948724269866943\n",
      "204: train loss is 81.06822204589844 & test loss is 6.093373775482178 & accuracy is %8.182008743286133\n",
      "205: train loss is 47.96278381347656 & test loss is 5.094135284423828 & accuracy is %15.890950202941895\n",
      "206: train loss is 46.86172866821289 & test loss is 6.480196475982666 & accuracy is %5.6229472160339355\n",
      "207: train loss is 60.32353973388672 & test loss is 5.356283664703369 & accuracy is %13.767833709716797\n",
      "208: train loss is 54.07598114013672 & test loss is 5.4845290184021 & accuracy is %12.849987030029297\n",
      "209: train loss is 62.02703857421875 & test loss is 5.289564609527588 & accuracy is %14.427891731262207\n",
      "210: train loss is 56.61135482788086 & test loss is 7.178069591522217 & accuracy is %-1.1640819311141968\n",
      "211: train loss is 88.76130676269531 & test loss is 7.290564060211182 & accuracy is %-1.1664201021194458\n",
      "212: train loss is 80.6785888671875 & test loss is 5.940042972564697 & accuracy is %9.03197193145752\n",
      "213: train loss is 64.39762878417969 & test loss is 8.382149696350098 & accuracy is %-8.608491897583008\n",
      "214: train loss is 100.11743927001953 & test loss is 6.055753231048584 & accuracy is %8.480002403259277\n",
      "215: train loss is 173.9608917236328 & test loss is 10.312714576721191 & accuracy is %-23.3089542388916\n",
      "216: train loss is 116.47038269042969 & test loss is 7.042652606964111 & accuracy is %0.049902889877557755\n",
      "217: train loss is 681.4521484375 & test loss is 49.50249099731445 & accuracy is %-184.3666229248047\n",
      "218: train loss is 527.0140380859375 & test loss is 28.550512313842773 & accuracy is %-113.93097686767578\n",
      "219: train loss is 972.7841186523438 & test loss is 28.20461082458496 & accuracy is %-125.19047546386719\n",
      "220: train loss is 702.8884887695312 & test loss is 36.37298583984375 & accuracy is %-146.591796875\n",
      "221: train loss is 471.984375 & test loss is 23.66075897216797 & accuracy is %-96.19084930419922\n",
      "222: train loss is 178.04701232910156 & test loss is 7.487162113189697 & accuracy is %-2.9916746616363525\n",
      "223: train loss is 75.29950714111328 & test loss is 5.028377056121826 & accuracy is %16.26178741455078\n",
      "224: train loss is 40.697994232177734 & test loss is 5.089323043823242 & accuracy is %16.09256935119629\n",
      "225: train loss is 40.347957611083984 & test loss is 5.263451099395752 & accuracy is %14.518647193908691\n",
      "226: train loss is 37.13531494140625 & test loss is 5.153001308441162 & accuracy is %15.373924255371094\n",
      "227: train loss is 114.39083862304688 & test loss is 7.634237766265869 & accuracy is %-3.5399858951568604\n",
      "228: train loss is 62.388587951660156 & test loss is 5.052818775177002 & accuracy is %16.251953125\n",
      "229: train loss is 58.81077194213867 & test loss is 6.911345958709717 & accuracy is %0.9172876477241516\n",
      "230: train loss is 316.4505310058594 & test loss is 11.716480255126953 & accuracy is %-33.24934768676758\n",
      "231: train loss is 205.7705535888672 & test loss is 13.259411811828613 & accuracy is %-38.8995246887207\n",
      "232: train loss is 169.51089477539062 & test loss is 7.21306848526001 & accuracy is %-1.0327062606811523\n",
      "233: train loss is 71.51424407958984 & test loss is 5.584253787994385 & accuracy is %12.086194038391113\n",
      "234: train loss is 41.296573638916016 & test loss is 4.620822429656982 & accuracy is %19.3958683013916\n",
      "235: train loss is 25.351688385009766 & test loss is 4.523341655731201 & accuracy is %19.53958511352539\n",
      "236: train loss is 32.47816467285156 & test loss is 4.920408725738525 & accuracy is %16.744985580444336\n",
      "237: train loss is 74.36685180664062 & test loss is 7.048318386077881 & accuracy is %0.505470871925354\n",
      "238: train loss is 182.020263671875 & test loss is 16.09996223449707 & accuracy is %-57.733184814453125\n",
      "239: train loss is 163.95347595214844 & test loss is 7.398155212402344 & accuracy is %-2.0164434909820557\n",
      "240: train loss is 67.33797454833984 & test loss is 5.428403854370117 & accuracy is %12.867033004760742\n",
      "241: train loss is 65.10597229003906 & test loss is 5.133366107940674 & accuracy is %15.20689582824707\n",
      "242: train loss is 77.43165588378906 & test loss is 11.481572151184082 & accuracy is %-27.773956298828125\n",
      "243: train loss is 168.80801391601562 & test loss is 9.437098503112793 & accuracy is %-16.48973846435547\n",
      "244: train loss is 128.28765869140625 & test loss is 13.812716484069824 & accuracy is %-33.93290710449219\n",
      "245: train loss is 165.86477661132812 & test loss is 8.041221618652344 & accuracy is %-7.628951072692871\n",
      "246: train loss is 100.64888763427734 & test loss is 9.21726131439209 & accuracy is %-15.9298095703125\n",
      "247: train loss is 112.44947052001953 & test loss is 6.453105449676514 & accuracy is %5.057431221008301\n",
      "248: train loss is 81.43104553222656 & test loss is 5.65178918838501 & accuracy is %11.809700965881348\n",
      "249: train loss is 50.65486526489258 & test loss is 5.883765697479248 & accuracy is %9.565961837768555\n",
      "250: train loss is 41.388816833496094 & test loss is 4.740931987762451 & accuracy is %18.256572723388672\n",
      "251: train loss is 31.183666229248047 & test loss is 5.004635334014893 & accuracy is %16.603851318359375\n",
      "252: train loss is 28.84958267211914 & test loss is 4.78557825088501 & accuracy is %16.99386215209961\n",
      "253: train loss is 46.931121826171875 & test loss is 5.860289096832275 & accuracy is %9.93673038482666\n",
      "254: train loss is 57.06669616699219 & test loss is 5.291220188140869 & accuracy is %14.049699783325195\n",
      "255: train loss is 44.235076904296875 & test loss is 5.091131687164307 & accuracy is %15.02386474609375\n",
      "256: train loss is 32.74457550048828 & test loss is 5.13551664352417 & accuracy is %15.043912887573242\n",
      "257: train loss is 32.253021240234375 & test loss is 4.823044776916504 & accuracy is %17.66492462158203\n",
      "258: train loss is 43.87517547607422 & test loss is 6.218739032745361 & accuracy is %7.893096446990967\n",
      "259: train loss is 43.884681701660156 & test loss is 5.093662738800049 & accuracy is %15.89780330657959\n",
      "260: train loss is 63.393272399902344 & test loss is 7.3130574226379395 & accuracy is %-1.632798433303833\n",
      "261: train loss is 1251.501708984375 & test loss is 400.39697265625 & accuracy is %-777.7973022460938\n",
      "262: train loss is 3273.322998046875 & test loss is 112.5003890991211 & accuracy is %-365.7783508300781\n",
      "263: train loss is 991.8311767578125 & test loss is 22.973176956176758 & accuracy is %-87.8365249633789\n",
      "264: train loss is 231.7053985595703 & test loss is 7.393142223358154 & accuracy is %-2.06536602973938\n",
      "265: train loss is 80.81362915039062 & test loss is 6.2566704750061035 & accuracy is %6.842402458190918\n",
      "266: train loss is 41.212608337402344 & test loss is 6.0063323974609375 & accuracy is %8.766809463500977\n",
      "267: train loss is 53.85893630981445 & test loss is 4.817117214202881 & accuracy is %17.05670166015625\n",
      "268: train loss is 26.62163734436035 & test loss is 4.520531177520752 & accuracy is %19.00503158569336\n",
      "269: train loss is 20.98711585998535 & test loss is 4.571893215179443 & accuracy is %18.528812408447266\n",
      "270: train loss is 21.691295623779297 & test loss is 4.496904373168945 & accuracy is %19.112777709960938\n",
      "271: train loss is 17.021560668945312 & test loss is 4.520877838134766 & accuracy is %18.78989601135254\n",
      "272: train loss is 18.17827796936035 & test loss is 4.4885334968566895 & accuracy is %18.66384506225586\n",
      "273: train loss is 16.820377349853516 & test loss is 4.478054523468018 & accuracy is %19.083843231201172\n",
      "274: train loss is 24.627655029296875 & test loss is 4.740482807159424 & accuracy is %17.526288986206055\n",
      "275: train loss is 25.832672119140625 & test loss is 4.851135730743408 & accuracy is %17.248653411865234\n",
      "276: train loss is 25.41103744506836 & test loss is 4.574864864349365 & accuracy is %18.78864860534668\n",
      "277: train loss is 20.565338134765625 & test loss is 4.469694137573242 & accuracy is %19.310997009277344\n",
      "278: train loss is 20.056591033935547 & test loss is 4.46583890914917 & accuracy is %19.004497528076172\n",
      "279: train loss is 16.479595184326172 & test loss is 4.4441237449646 & accuracy is %18.89287757873535\n",
      "280: train loss is 15.21996784210205 & test loss is 4.483058929443359 & accuracy is %18.535310745239258\n",
      "281: train loss is 18.684389114379883 & test loss is 4.4693827629089355 & accuracy is %18.861915588378906\n",
      "282: train loss is 15.791596412658691 & test loss is 4.444077968597412 & accuracy is %18.846467971801758\n",
      "283: train loss is 16.805805206298828 & test loss is 4.450808048248291 & accuracy is %18.5358829498291\n",
      "284: train loss is 15.829980850219727 & test loss is 4.47294282913208 & accuracy is %19.0593204498291\n",
      "285: train loss is 18.080591201782227 & test loss is 4.443050861358643 & accuracy is %18.912128448486328\n",
      "286: train loss is 16.497451782226562 & test loss is 4.447895050048828 & accuracy is %18.720609664916992\n",
      "287: train loss is 15.417851448059082 & test loss is 4.440831661224365 & accuracy is %18.813364028930664\n",
      "288: train loss is 16.39240837097168 & test loss is 4.582507133483887 & accuracy is %18.182212829589844\n",
      "289: train loss is 18.235219955444336 & test loss is 4.467840671539307 & accuracy is %19.068452835083008\n",
      "290: train loss is 15.27868938446045 & test loss is 4.434131622314453 & accuracy is %18.844417572021484\n",
      "291: train loss is 15.718155860900879 & test loss is 4.43940544128418 & accuracy is %18.47380256652832\n",
      "292: train loss is 15.820694923400879 & test loss is 4.4562907218933105 & accuracy is %18.72553253173828\n",
      "293: train loss is 22.904232025146484 & test loss is 4.533940315246582 & accuracy is %18.917264938354492\n",
      "294: train loss is 47.71931838989258 & test loss is 5.825083255767822 & accuracy is %9.765725135803223\n",
      "295: train loss is 33.70254898071289 & test loss is 4.630388259887695 & accuracy is %18.53707504272461\n",
      "296: train loss is 20.981307983398438 & test loss is 4.448707103729248 & accuracy is %19.14728355407715\n",
      "297: train loss is 16.99920082092285 & test loss is 4.527318954467773 & accuracy is %18.488801956176758\n",
      "298: train loss is 34.23577117919922 & test loss is 5.102273941040039 & accuracy is %14.668745994567871\n",
      "299: train loss is 136.2239990234375 & test loss is 10.24332332611084 & accuracy is %-19.174978256225586\n"
     ]
    }
   ],
   "source": [
    "batch_size = 40\n",
    "train_Losses=[]\n",
    "test_Losses=[]\n",
    "N_train = int(np.floor(X_train.size(0)/batch_size))\n",
    "N_test = int(np.floor(X_test.size(0)/batch_size))\n",
    "\n",
    "for epoch in range(300):\n",
    "    model.train()\n",
    "    train_loss=torch.tensor(0,dtype=torch.float32)\n",
    "    for i in range(N_train):\n",
    "        x = torch.flatten(X_train[i*batch_size:(i+1)*batch_size,:,:],start_dim=1)\n",
    "        y = Y_train[i*batch_size:(i+1)*batch_size,:]\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss_train = LossFn(y,out)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss_train.detach().item()\n",
    "    train_Losses.append( train_loss/N_train )\n",
    "   \n",
    "    model.eval()\n",
    "    test_loss=torch.tensor(0,dtype=torch.float32)\n",
    "    test_acc=torch.tensor(0,dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        for i in range(N_test):\n",
    "            x = torch.flatten(X_test[i*batch_size:(i+1)*batch_size,:,:],start_dim=1)\n",
    "            y = Y_test[i*batch_size:(i+1)*batch_size,:].detach()\n",
    "            out = model(x)\n",
    "            loss_test = LossFn(y,out)\n",
    "            test_loss += loss_test.detach().item()\n",
    "            temp=y-out\n",
    "            test_acc += torch.sum(1 - torch.abs(y-out)/2.0).detach().item()\n",
    "    test_Losses.append( test_loss/N_test )\n",
    "    accuracy = test_acc / (N_test*batch_size*days_predict) *100\n",
    "    print(f'{epoch}: train loss is {train_Losses[epoch]} & test loss is {test_Losses[epoch]} & accuracy is %{accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.8854, device='cuda:0') tensor(-0.1974, device='cuda:0')\n",
      "tensor(4.3821, device='cuda:0') tensor(-0.6184, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.var(Y_train),torch.mean(Y_train))\n",
    "print(torch.var(Y_test),torch.mean(Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
